filter(str_detect(collocation, "crisis")) %>%
arrange(desc(count))
tok1
tok1$ara_2022.txt
text %>%
unnest_ngrams("bigram", text, n = 2)
text %>%
unnest_ngrams("bigram", text, n = 2)
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
filter(year == 2022)
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
filter(year == 2022) %>%
count(bigram, sort = TRUE)
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
filter(year == 2022) %>%
count(bigram, sort = TRUE) %>%
filter(str_detect(bigram, "crisis"))
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Befor 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE)
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE)
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n = 10)
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 10)
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 5)
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 5) %>%
ggplot(aes(reorder_within(bigram, n, period))) +
geom_col()
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 5) %>%
ggplot(aes(reorder_within(bigram, n, period), n, fill = period)) +
geom_col()
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 5) %>%
ggplot(aes(reorder_within(bigram, n, period), n, fill = period)) +
geom_col() +
coord_flip() +
facet_wrap(~period) +
scale_x_reordered()
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 5) %>%
ggplot(aes(reorder_within(bigram, n, period), n, fill = period)) +
geom_col() +
coord_flip() +
facet_wrap(~period, scale = "free") +
scale_x_reordered()
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 5) %>%
ggplot(aes(reorder_within(bigram, n, period), n, fill = period)) +
geom_col() +
coord_flip() +
facet_wrap(~period, scale = "free") +
scale_x_reordered() +
labs(title = "Collocation of the term crisis with other terms by period",
x = NULL, y = NULL) +
theme(legend.position = "none")
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 5) %>%
ggplot(aes(reorder_within(bigram, n, period), n, fill = period)) +
geom_col() +
coord_flip() +
facet_wrap(~period, scale = "free") +
scale_x_reordered() +
labs(title = "Colocation of the term crisis with other terms by period",
x = NULL, y = NULL) +
theme(legend.position = "none")
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 5) %>%
ggplot(aes(reorder_within(bigram, n, period), n, fill = period)) +
geom_col() +
coord_flip() +
facet_wrap(~period, scale = "free") +
scale_x_reordered() +
labs(title = "Colocation of the term 'crisis' with other terms by period",
x = NULL, y = NULL) +
theme(legend.position = "none")
text %>%
unnest_ngrams("bigram", text, n = 2) %>%
mutate(period = ifelse(year < 2022, "Before 2022", "In 2022")) %>%
filter(str_detect(bigram, "crisis")) %>%
group_by(period) %>%
count(bigram, sort = TRUE) %>%
slice_max(n, n = 3) %>%
ggplot(aes(reorder_within(bigram, n, period), n, fill = period)) +
geom_col() +
coord_flip() +
facet_wrap(~period, scale = "free") +
scale_x_reordered() +
labs(title = "Colocation of the term 'crisis' with other terms by period",
x = NULL, y = NULL) +
theme(legend.position = "none")
text %>%
mutate(year = as.numeric(str_extract(doc_id,"\\d{4}"))) %>%
unnest_tokens("words", text) %>%
filter(str_detect(words, "crisis")) %>%
group_by(year) %>%
count(words) %>%
ggplot(aes(year, n, color = words)) +
geom_line()
text %>%
mutate(year = as.numeric(str_extract(doc_id,"\\d{4}"))) %>%
unnest_tokens("words", text) %>%
filter(str_detect(words, "victim")) %>%
group_by(year) %>%
count(words) %>%
ggplot(aes(year, n, color = words)) +
geom_line()
text %>%
mutate(year = as.numeric(str_extract(doc_id,"\\d{4}"))) %>%
unnest_tokens("words", text) %>%
filter(str_detect(words, "human")) %>%
group_by(year) %>%
count(words) %>%
ggplot(aes(year, n, color = words)) +
geom_line()
library(readtext)
library(dplyr)
library(tidytext)
library(stringr)
library(ggplot2)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(quanteda.textmodels)
library(factoextra)
# Donn√©es----
text <-
readtext("MyData/to_clean/*.txt") %>%
tibble() %>%
slice(-1:-3) %>%
mutate(year = as.numeric(str_extract(doc_id, "\\d{4}")),
text = str_to_lower(text),
text = str_replace_all(text, "\\s+", " "),
text = str_replace_all(text, "([A-Za-z]+)\\-\\s", "\\1"),
text = str_remove_all(text, "\xad"),
text = str_remove_all(text, "(annual\\s)?risk\\sanalysis(\\s(for|of))?\\s\\d{4}"),
text = str_remove_all(text, "\\d+\\sof\\s\\d+"),
text = if_else(year %in% c(2013:2015, 2022),
str_remove(text, "^.+(?=executive\\ssummary(?!\\s+\\#))"),
str_remove(text, "^.+(?=\\d\\.\\s+summary(?!\\s+\\#))")),
text = if_else(year < 2022,
str_remove(text, "\\d{1,2}(\\.)?\\s+statistical\\sannex.+$"),
str_remove(text, "annex\\s+\\-\\s+methodological\\snote.+$")),
text = str_replace_all(text, "(bor)\\s(ders?)", "\\1\\2"),
text = str_replace_all(text, "([a-z]{2,})\\s(ing)", "\\1\\2"),
text = str_replace_all(text, "([a-z]{4,})\\s(ities?|ment)", "\\1\\2"),
text = str_replace_all(text, "(ac)\\s([a-z]{4,})", "\\1\\2"),
text = str_replace_all(text, "(indica|fac|facilita)\\s(tors?)", "\\1\\2"),
text = str_replace_all(text, "(re)\\s(ported)", "\\1\\2"),
text = str_replace_all(text, "([a-z]{2,})(frontex)?\\s(tions?)", "\\1\\3"),
text = str_replace_all(text, "(sit)\\s(uation)", "\\1\\2"),
text = str_replace_all(text, "(mem|num)\\s(bers?)", "\\1\\2"),
text = str_replace_all(text, "(pos)\\s(sible)", "\\1\\2"),
text = str_replace_all(text, "(pas)\\s(sengers)", "\\1\\2"),
text = str_replace_all(text, "(mo)\\s(rocco)", "\\1\\2"),
text = str_replace_all(text, "(pub)\\s(lic|lished)", "\\1\\2"),
text = str_replace_all(text, "(infec)\\s(tious)", "\\1\\2"),
text = str_replace_all(text, "(indi)\\s(cators?|cating|vidual|cates?)", "\\1\\2"),
text = str_replace_all(text, "(mi)\\s(frontex\\s)?(grants?|gration|gratory)", "\\1\\3"),
text = str_replace_all(text, "(de)(frontex)?\\s(tections?)", "\\1\\3"),
text = str_replace_all(text, "(secu)\\s(rity)", "\\1\\2"),
text = str_replace_all(text, "(schen)\\s(gen)", "\\1\\2"),
text = str_replace_all(text, "(exter)\\s(nal)", "\\1\\2"),
text = str_replace_all(text, "(af)\\s(ricans?)", "\\1\\2"),
text = str_replace_all(text, "(consid|recov)\\s(ered)", "\\1\\2"),
text = str_replace_all(text, "(differ|consist)\\s(ent)", "\\1\\2"),
text = str_replace_all(text, "\\bren\\b", "return"),
text = str_remove_all(text, "\\baa\\b|\\btur\\b|\\bn\\.a\\b|\\bgrc\\b|\\bju\\b"),
text = str_remove_all(text, "n\\sm\\sar\\sm\\say\\sju\\sl\\sse\\sp\\sn\\sov"),
text = str_remove_all(text, "\\b\\-(?=[a-z]+)"),
text = str_remove_all(text, "fig\\.?\\s+\\d{1,2}")) %>%
select(doc_id, year, text)
# Rapid----
save(text, file = "MyData/text.Rda")
corp <- corpus(text)
save(corp, file = "MyData/corp.Rda")
tok1 <-
tokens(corp, remove_punct = TRUE)
tok2 <-
tokens(corp, remove_punct = TRUE) %>%
tokens_wordstem("english")
save(tok1, tok3, file = "MyData/quanteda_tokens.Rda")
mon_dfm <-
dfm(tok2) %>%
dfm_remove(stopwords("en", source = "stopwords-iso")) %>%
dfm_remove("\\d+", valuetype = "regex") %>%
dfm_remove("https?.*", valuetype = "regex") %>%
dfm_trim(min_termfreq = 50)
save(mon_dfm, file = "MyData/dfm.Rda")
tok3 <-
text %>%
mutate(text = str_remove_all(text, "\\d+|https?.*")) %>%
unnest_tokens("words", text) %>%
mutate(doc_id = str_remove_all(doc_id, "\\.txt"),
year = str_extract(doc_id, "\\d{4}")) %>%
filter(!(words %in% stopwords("en", "stopwords-iso")))
save(tok3, file = "MyData/tidytext_tokens.Rda")
# GGwordcloud----
library(ggwordcloud)
tok3 %>%
count(words, sort = TRUE) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud()
tok3 %>%
count(words, sort = TRUE) %>%
summary()
tok3 %>%
count(words, sort = TRUE) %>%
filter(n > 10) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n= 50) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n= 50) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud() +
theme_minimal()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 5) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud() +
theme_minimal()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 1) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud() +
theme_minimal()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 1)
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 1) %>%
ggplot(aes(label = words)) +
geom_text_wordcloud() +
theme_minimal()
library(readtext)
library(dplyr)
library(tidytext)
library(stringr)
library(ggplot2)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(quanteda.textmodels)
library(factoextra)
# GGwordcloud----
library(ggwordcloud)
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 1) %>%
ggplot(aes(label = words)) +
geom_text_wordcloud() +
theme_minimal()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 50) %>%
ggplot(aes(label = words)) +
geom_text_wordcloud() +
theme_minimal()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 50) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud() +
theme_minimal()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 100) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud() +
theme_minimal()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 100) %>%
ggplot(aes(label = words, size = n, color = "red")) +
geom_text_wordcloud() +
theme_minimal()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 100) %>%
ggplot(aes(label = words, size = n, color = "red")) +
geom_text_wordcloud_area() +
theme_minimal()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 100) %>%
ggplot(aes(label = words, size = n, color = "red")) +
geom_text_wordcloud_area() +
theme_minimal() +
theme(plot.background = element_rect(fill = "darkblue"))
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 100) %>%
ggplot(aes(label = words, size = n, color = "white")) +
geom_text_wordcloud_area() +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 100) %>%
ggplot(aes(label = words, size = n, color = "white")) +
geom_text_wordcloud() +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 500) %>%
ggplot(aes(label = words, size = n, color = "white")) +
geom_text_wordcloud() +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 300) %>%
ggplot(aes(label = words, size = n, color = "white")) +
geom_text_wordcloud(
mask = png::readPNG(system.file("MyData/flag.png",
package = "ggwordcloud",
mustWork = TRUE)),
rm_outside = TRUE
) +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
getwd()
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 300) %>%
ggplot(aes(label = words, size = n, color = "white")) +
geom_text_wordcloud(
mask = png::readPNG(system.file("MyData/flag.png",
package = "ggwordcloud",
mustWork = TRUE)),
rm_outside = TRUE
) +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 300) %>%
ggplot(aes(label = words, size = n, color = "white")) +
geom_text_wordcloud(
mask = png::readPNG("MyData/flag.png"),
rm_outside = TRUE
) +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 500) %>%
ggplot(aes(label = words, size = n, color = "white")) +
geom_text_wordcloud(
mask = png::readPNG("MyData/flag.png"),
rm_outside = TRUE
) +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
tok3 %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 500) %>%
ggplot(aes(label = words, size = n, color = "white")) +
geom_text_wordcloud(
mask = png::readPNG("MyData/flag.png"),
rm_outside = TRUE
) +
scale_size_area(max_size = 20) +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
tok3 %>%
filter(!(words %in% c("aa", "i.e", "thb"))) %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 500) %>%
ggplot(aes(label = words, size = n, color = "white")) +
geom_text_wordcloud(
mask = png::readPNG("MyData/flag.png"),
rm_outside = TRUE
) +
scale_size_area(max_size = 20) +
theme_minimal() +
theme(plot.background = element_rect(fill = "black"))
tok3 %>%
filter(!(words %in% c("aa", "i.e", "thb"))) %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 500) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud(
mask = png::readPNG("MyData/flag.png"),
rm_outside = TRUE, color = "white"
) +
scale_size_area(max_size = 20) +
theme_minimal() +
theme(plot.background = element_rect(fill = "black"))
tok3 %>%
filter(!(words %in% c("aa", "i.e", "thb", "'s", "e.g"))) %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 500) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud(
mask = png::readPNG("MyData/flag.png"),
rm_outside = TRUE, color = "white"
) +
scale_size_area(max_size = 15) +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
tok3 %>%
filter(!(words %in% c("aa", "i.e", "thb", "'s", "e.g"))) %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 500) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud(
mask = png::readPNG("MyData/flag.png"),
rm_outside = TRUE, color = "white"
) +
scale_size_area(max_size = 10) +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
tok3 %>%
filter(!(words %in% c("aa", "i.e", "thb", "'s", "e.g"))) %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 500) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud(
mask = png::readPNG("MyData/flag.png"),
rm_outside = TRUE, color = "white"
) +
scale_size_area() +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
?scale_size_area
tok3 %>%
filter(!(words %in% c("aa", "i.e", "thb", "'s", "e.g"))) %>%
count(words, sort = TRUE) %>%
slice_max(n, n = 500) %>%
ggplot(aes(label = words, size = n)) +
geom_text_wordcloud(
mask = png::readPNG("MyData/flag.png"),
rm_outside = TRUE, color = "white"
) +
scale_size_area(max_size = 8) +
theme_minimal() +
theme(plot.background = element_rect(fill = "red"))
